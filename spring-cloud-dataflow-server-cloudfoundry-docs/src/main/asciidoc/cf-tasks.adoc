[[tasks-on-cloudfoundry]]
= Tasks on Cloud Foundry

Spring Cloud Data Flow's task functionality exposes new task capabilities within
the Pivotal Cloud Foundry runtime.

== Version Compatibility

The task functionality depends on the latest versions of PCF for runtime support. This
release requires PCF version 1.7.12 or higher to run tasks. Tasks are an experimental
feature in PCF 1.7 and 1.8 and a GA feature in PCF 1.9.

== Running Task Applications

Running a task application within Spring Cloud Data Flow goes through a slightly different
lifecycle than running a stream application. Both types of applications need to be registered
with the appropriate artifact coordinates. Both need a definition created with the SCDF DSL.
However, the similarities end there.

With stream-based applications, you "`deploy`" them with the intent that they run until they
are undeployed. A stream definition is only deployed once (it can be scaled, but only
deployed as one instance of the stream as a whole). However, tasks are "`launched`". A single
task definition can be launched many times. With each launch, the task starts, runs,
and shuts down, with PCF cleaning up the resources once the shutdown has occurred. The
following sections outline the process of creating, launching, destroying, and viewing tasks.

=== Creating a Task

Similar to streams, creating a task application is done by using the SCDF DSL or through the
dashboard. To create a task definition in SCDF, you must either develop a task
application or use one of the out-of-the-box link:https://docs.spring.io/spring-cloud-task-app-starters/docs/{sct-starters-core-version}/reference/htmlsingle[task app-starters].
The maven coordinates of the task application should be registered in SCDF. For more
details on how to register task applications, see link:https://docs.spring.io/spring-cloud-dataflow/docs/{scdf-core-version}/reference/htmlsingle/#spring-cloud-dataflow-register-task-apps[Registering a Task Application]
in the core docs.

The following example uses the out-of-the-box `timestamp` task application:

====
[source]
----
dataflow:>task create --name foo --definition "timestamp"
Created new task 'foo'
----
====

NOTE: Tasks in SCDF do not require explicit deployment. They are required to be launched,
and there are different ways to launch them - see https://docs.spring.io/spring-cloud-task/docs/current/reference/htmlsingle/#stream-integration-launching-sink[Launching Tasks from a Spring Cloud Stream] for more details.

=== Launching a Task

Unlike streams, tasks in SCDF require an explicit launch trigger or can be manually kicked-off. The following example shows how to launch a task called `mytask`

====
[source]
----
dataflow:>task launch mytask
Launched task 'mytask'
----
====

=== Launching a Task with Arguments and Properties

When you launch a task, you can set any properties that need to be passed as command line arguments to the task application when launching the task as follows:

====
[source,bash]
----
dataflow:>task launch mytask --arguments "--key1=value1,--key2=value2"
----
====

You can pass in additional properties meant for a `TaskLauncher` itself by using a `--properties` option.
The format of this option is a comma-separated string of properties prefixed with `app.<task definition name>.<property>`.
Properties are passed to `TaskLauncher` as application properties.
It is up to an implementation to choose how those are passed into an actual task application.
If the property is prefixed with `deployer` instead of `app`, it is passed to `TaskLauncher` as a deployment property and its meaning may be specific to the `TaskLauncher` implementation. The following example shows how to pass in application properties:

====
[source,bash]
----
dataflow:>task launch mytask --properties "deployer.timestamp.custom1=value1,app.timestamp.custom2=value2"
----
====

You can also pass JAVA_OPTS values as the CF deployer property when the task is launched, as the following example shows

====
[source,bash]
----
task launch --name mytask --properties "deployer.mytask.cloudfoundry.javaOpts=-Duser.timezone=America/New_York"
----
====

You can also set the JAVA_OPTS values as the global property for all the tasks by using
`SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_TASK_JAVA_OPTS`

=== Viewing Task Logs

The CF CLI is the way to interact with tasks on PCF,
including viewing the logs. In order to view the logs as a task is executing, you can use the
following command, where `mytask` is the name of the task you are executing:

====
[source,bash]
----
cf v3-logs mytask
Tailing logs for app mytask...

....
....
....
....

2016-08-19T09:44:49.11-0700 [APP/TASK/bar1/0]OUT 2016-08-19 16:44:49.111  INFO 7 --- [           main] o.s.c.t.a.t.TimestampTaskApplication     : Started TimestampTaskApplication in 2.734 seconds (JVM running for 3.288)
2016-08-19T09:44:49.13-0700 [APP/TASK/bar1/0]OUT Exit status 0
2016-08-19T09:44:49.19-0700 [APP/TASK/bar1/0]OUT Destroying container
2016-08-19T09:44:50.41-0700 [APP/TASK/bar1/0]OUT Successfully destroyed container
----
====

NOTE: Logs are viewable only through the CF CLI as the app is running. Historic
logs are not available.

=== Listing Tasks

Listing tasks is as simple as the following example (which includes output):

====
[source]
----
dataflow:>task list
╔══════════════════════╤═════════════════════════╤═══════════╗
║      Task Name       │     Task Definition     │Task Status║
╠══════════════════════╪═════════════════════════╪═══════════╣
║foo                   │timestamp                │complete   ║
╚══════════════════════╧═════════════════════════╧═══════════╝
----
====

=== Listing Task Executions

If you want to view the execution details of the launched task, you could run the following:

====
[source]
----
dataflow:>task execution list
╔════════════════════════╤══╤═════════════════════════╤═════════════════════════╤════════╗
║       Task Name        │ID│       Start Time        │        End Time         │  Exit  ║
║                        │  │                         │                         │  Code  ║
╠════════════════════════╪══╪═════════════════════════╪═════════════════════════╪════════╣
║foo:cloud:              │1 │ Fri Aug 19 09:44:49 PDT │Fri Aug 19 09:44:49 PDT  │0       ║
╚════════════════════════╧══╧═════════════════════════╧═════════════════════════╧════════╝
----
====

=== Destroying a Task

Destroying the task application from SCDF removes the task definition from the task repository. The following listing (which includes output) shows how to destroy a task named `mytask` and verify that it has been removed from the task list:

[source]
----
dataflow:>task destroy mytask
Destroyed task 'mytask'
dataflow:>task list
╔═════════╤═══════════════╤═══════════╗
║Task Name│Task Definition│Task Status║
╚═════════╧═══════════════╧═══════════╝
----

=== Deleting a Task From Cloud Foundry

Currently, Spring Cloud Data Flow does not delete tasks deployed on a Cloud
Foundry instance once they have been pushed. The only way to do this now is through the
CLI on a Cloud Foundry instance, version 1.9 or above.
This is done in two steps:

. Obtain a list of the apps by using the `cf apps` command.
. Identify the task application to be deleted and run the `cf delete <task-name>`
command.

NOTE: The `task destroy <task-name>` deletes only the definition and not the task
deployed on Cloud Foundry.
